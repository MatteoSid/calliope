port: 3100
base_url: "http://127.0.0.1"

# rabbitmq:
#   stt_queue: "stt"
#   mmer_queue: "mmer"
#   gpt_queue: "gpt"
#   videosmith_queue: "videosmith"

mongodb:
  host: "127.0.0.1"
  port: 27018
  db_name: "calliope"
  users_collection: "users_db"
  groups_collection: "groups_db"
  messages_collection: "messages"

llm:
  provider: "openai"  # Options: "openai", "ollama", "vllm"
  openai_api_key: ${OPENAI_API_KEY} # To be read from env
  ollama_api_url: ${OLLAMA_API_URL:-http://localhost:11434} # Default if not set
  vllm_api_url: ${VLLM_API_URL:-http://localhost:8000}    # Default if not set
